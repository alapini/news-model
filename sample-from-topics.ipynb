{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import norm\n",
    "from numba import jit\n",
    "import random\n",
    "import multiprocessing\n",
    "import re\n",
    "from operator import itemgetter\n",
    "\n",
    "import logging\n",
    "from collections import defaultdict\n",
    "from functools import lru_cache\n",
    "from pathlib import Path\n",
    "from numba import jit\n",
    "import numpy as np\n",
    "\n",
    "import spacy\n",
    "from bson.objectid import ObjectId\n",
    "from gensim.models import KeyedVectors\n",
    "from nltk.corpus import stopwords\n",
    "from pymongo import MongoClient\n",
    "from tqdm import tqdm\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(message)s', level=logging.INFO)\n",
    "_info = logging.info\n",
    "\n",
    "client = MongoClient('mongodb://localhost:27017')\n",
    "db = client.twitter_news\n",
    "nlp = spacy.load('en_core_web_sm', tagger=False, entity=False, matcher=False)\n",
    "\n",
    "def hashtag_pipe(doc):\n",
    "    merged_hashtag = False\n",
    "    while True:\n",
    "        for token_index, token in enumerate(doc):\n",
    "            if token.text == '#':\n",
    "                if token.head is not None:\n",
    "                    start_index = token.idx\n",
    "                    end_index = start_index + len(token.head.text) + 1\n",
    "                    if doc.merge(start_index, end_index) is not None:\n",
    "                        merged_hashtag = True\n",
    "                        break\n",
    "        if not merged_hashtag:\n",
    "            break\n",
    "        merged_hashtag = False\n",
    "    return doc\n",
    "\n",
    "\n",
    "nlp.add_pipe(hashtag_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_events = 3\n",
    "\n",
    "\n",
    "@lru_cache(maxsize=total_events)\n",
    "def get_representatives(event_id):\n",
    "    _info(\"getting representatives\")\n",
    "    representatives = db.representatives.find({'event': ObjectId(event_id)})\n",
    "    return list(representatives)\n",
    "\n",
    "\n",
    "@lru_cache(maxsize=total_events)\n",
    "def get_topics(event_id):\n",
    "    _info(\"getting topics\")\n",
    "    topics = list(db.topics.find({'event': ObjectId(event_id)}))\n",
    "    comodin = None\n",
    "    for t in topics:\n",
    "        if t['topic_name'] == \"Non relevant\":\n",
    "            comodin = t\n",
    "            topics.remove(t)\n",
    "            break\n",
    "    return topics, comodin\n",
    "\n",
    "\n",
    "@lru_cache(maxsize=1)\n",
    "def get_events():\n",
    "    _info(\"getting events\")\n",
    "    events = db.events.find()\n",
    "    return list(events)\n",
    "\n",
    "\n",
    "@lru_cache(maxsize=1)\n",
    "def get_tweets(a=None):\n",
    "    _info('getting all tweets')\n",
    "    all_tweets = db.tweets.find()\n",
    "    return list(all_tweets)\n",
    "\n",
    "\n",
    "@lru_cache(maxsize=3)\n",
    "def get_vectors(path):\n",
    "    _info(f\"loading fasttext vectors from {path}\")\n",
    "    word_vectors = KeyedVectors.load_word2vec_format(path)\n",
    "    return word_vectors\n",
    "\n",
    "\n",
    "@lru_cache(maxsize=2**30)\n",
    "def sim(tokens_a, tokens_b):\n",
    "    return ft_comp.n_similarity(tokens_a, tokens_b)\n",
    "\n",
    "\n",
    "def mmr(docs, query, l):\n",
    "    def mmr_score(tweet):\n",
    "        return l * sim(docs[tweet], query) - \\\n",
    "               (1 - l) * max([sim(docs[tweet], docs[y]) for y in set(selected) - {tweet}] or [0])\n",
    "\n",
    "    L = np.array([[l, 0], [0, l - 1]])\n",
    "\n",
    "    def score(tweet):\n",
    "        s1 = sim(docs[tweet], query)\n",
    "        s2 = np.max(np.array([sim(docs[tweet], docs[y]) for y in set(selected) - {tweet}] or [0]))\n",
    "\n",
    "        return L.dot(np.array([s1, s2])).sum()\n",
    "\n",
    "    selected = set()\n",
    "    while selected != set(docs):\n",
    "        remaining = list(set(docs) - selected)\n",
    "        next_selected = max(remaining, key=mmr_score)\n",
    "        # next_selected = remaining[np.argmax([score(t) for t in remaining])]\n",
    "\n",
    "        # next_selected = None\n",
    "        # max_score = 0\n",
    "        #\n",
    "        # for _t in remaining:\n",
    "        #     score = l * sim(docs[_t], query) - \\\n",
    "        #             (1 - l) * max([sim(docs[_t], docs[y]) for y in set(selected) - {_t}] or [0])\n",
    "        #     if score > max_score:\n",
    "        #         max_score = score\n",
    "        #         next_selected = _t\n",
    "\n",
    "        selected.add(next_selected)\n",
    "        yield next_selected, ' '.join(list(docs[next_selected]))\n",
    "\n",
    "\n",
    "@lru_cache(maxsize=total_events)\n",
    "def process_tweets(event_id):\n",
    "    all_tweets = get_tweets()\n",
    "    representatives = get_representatives(event_id)\n",
    "\n",
    "    _info(\"processing tweets\")\n",
    "\n",
    "    # rep_tweet: repr_id => tweet\n",
    "    rep_tweet = dict()\n",
    "    for t in tqdm(all_tweets):\n",
    "        rep_tweet[t['representative']] = t\n",
    "\n",
    "    # repr_ids: {repr_id} // this event\n",
    "    repr_ids = set([r['_id'] for r in representatives])\n",
    "\n",
    "    # tweets_this_event: [tweet]\n",
    "    tweets_this_event_ = [t for r, t in rep_tweet.items() if r in repr_ids]\n",
    "    tweets_this_event = []\n",
    "    \n",
    "    # filter out tweets wo expanded urls\n",
    "    for t in tweets_this_event_:\n",
    "        e_u = t['expanded_urls']\n",
    "        if all(u is not None for u in e_u):\n",
    "            tweets_this_event.append(t)    \n",
    "\n",
    "    tweets_tokens = dict()\n",
    "    all_tokens = set()\n",
    "    for tweet, doc in tqdm(zip(tweets_this_event, nlp.pipe([_t['text'] for _t in tweets_this_event],\n",
    "                                                           n_threads=8)),\n",
    "                           total=len(tweets_this_event)):\n",
    "\n",
    "        tokens = frozenset([token.lower_\n",
    "                            for token in doc\n",
    "                            if token.lower_ not in stopwords.words('english') and token.lower_ in ft_comp])\n",
    "\n",
    "        if tokens and tokens not in all_tokens:\n",
    "            tweets_tokens[str(tweet['_id'])] = tokens\n",
    "            all_tokens.add(tokens)\n",
    "\n",
    "    return tweets_tokens\n",
    "\n",
    "\n",
    "def expand_query(topics):\n",
    "    # query expansion \n",
    "    topics_this_event = []\n",
    "    for topic in topics:\n",
    "        new_words = set()\n",
    "        for keyword in topic:\n",
    "            new_words |= set([word for word, _ in ft_comp.most_similar(keyword, topn=25)])\n",
    "        new_topic = set(topic) | new_words\n",
    "        topics_this_event.append(new_topic)\n",
    "    return topics_this_event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('/home/mquezada/anchor-text-twitter/data/ft_alltweets_model.vec')\n",
    "data_path = Path('/home/mquezada/tweet_topics/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mquezada/tweet_topics/event_5b171726da870923dcb04791-topic_5b19af21da87097532fd0488-tweet_ids_sorted_mmr.txt\n",
      "5b171726da870923dcb04791 5b19af21da87097532fd0488\n",
      "/home/mquezada/tweet_topics/event_5b171725da870923dcb0478f-topic_5b184131da870950572be268-tweet_ids_sorted_mmr.txt\n",
      "5b171725da870923dcb0478f 5b184131da870950572be268\n",
      "/home/mquezada/tweet_topics/event_5b171726da870923dcb04790-topic_5b19ae78da870974f0f58bbe-tweet_ids_sorted_mmr.txt\n",
      "5b171726da870923dcb04790 5b19ae78da870974f0f58bbe\n",
      "/home/mquezada/tweet_topics/event_5b171726da870923dcb04790-topic_5b19ae8dda870974f0f58bc2-tweet_ids_sorted_mmr.txt\n",
      "5b171726da870923dcb04790 5b19ae8dda870974f0f58bc2\n",
      "/home/mquezada/tweet_topics/event_5b171726da870923dcb04791-topic_5b19af32da87097532fd048a-tweet_ids_sorted_mmr.txt\n",
      "5b171726da870923dcb04791 5b19af32da87097532fd048a\n",
      "/home/mquezada/tweet_topics/event_5b171726da870923dcb04791-topic_5b19af1bda87097532fd0487-tweet_ids_sorted_mmr.txt\n",
      "5b171726da870923dcb04791 5b19af1bda87097532fd0487\n",
      "/home/mquezada/tweet_topics/event_5b171725da870923dcb0478f-topic_5b18410fda870950572be265-tweet_ids_sorted_mmr.txt\n",
      "5b171725da870923dcb0478f 5b18410fda870950572be265\n",
      "/home/mquezada/tweet_topics/event_5b171726da870923dcb04790-topic_5b19ae1ada870974f0f58bbc-tweet_ids_sorted_mmr.txt\n",
      "5b171726da870923dcb04790 5b19ae1ada870974f0f58bbc\n",
      "/home/mquezada/tweet_topics/event_5b171726da870923dcb04791-topic_5b19af48da87097532fd048b-tweet_ids_sorted_mmr.txt\n",
      "5b171726da870923dcb04791 5b19af48da87097532fd048b\n",
      "/home/mquezada/tweet_topics/event_5b171726da870923dcb04790-topic_5b19aea1da870974f0f58bc5-tweet_ids_sorted_mmr.txt\n",
      "5b171726da870923dcb04790 5b19aea1da870974f0f58bc5\n",
      "/home/mquezada/tweet_topics/event_5b171726da870923dcb04790-topic_5b19ae98da870974f0f58bc4-tweet_ids_sorted_mmr.txt\n",
      "5b171726da870923dcb04790 5b19ae98da870974f0f58bc4\n",
      "/home/mquezada/tweet_topics/event_5b171726da870923dcb04790-topic_5b19ae7cda870974f0f58bbf-tweet_ids_sorted_mmr.txt\n",
      "5b171726da870923dcb04790 5b19ae7cda870974f0f58bbf\n",
      "/home/mquezada/tweet_topics/event_5b171726da870923dcb04791-topic_5b19af0cda87097532fd0484-tweet_ids_sorted_mmr.txt\n",
      "5b171726da870923dcb04791 5b19af0cda87097532fd0484\n",
      "/home/mquezada/tweet_topics/event_5b171725da870923dcb0478f-topic_5b18413eda870950572be269-tweet_ids_sorted_mmr.txt\n",
      "5b171725da870923dcb0478f 5b18413eda870950572be269\n",
      "/home/mquezada/tweet_topics/event_5b171725da870923dcb0478f-topic_5b18412bda870950572be267-tweet_ids_sorted_mmr.txt\n",
      "5b171725da870923dcb0478f 5b18412bda870950572be267\n",
      "/home/mquezada/tweet_topics/event_5b171726da870923dcb04790-topic_5b19ae8bda870974f0f58bc1-tweet_ids_sorted_mmr.txt\n",
      "5b171726da870923dcb04790 5b19ae8bda870974f0f58bc1\n",
      "/home/mquezada/tweet_topics/event_5b171726da870923dcb04790-topic_5b19ae68da870974f0f58bbd-tweet_ids_sorted_mmr.txt\n",
      "5b171726da870923dcb04790 5b19ae68da870974f0f58bbd\n",
      "/home/mquezada/tweet_topics/event_5b171725da870923dcb0478f-topic_5b18415bda870950572be26a-tweet_ids_sorted_mmr.txt\n",
      "5b171725da870923dcb0478f 5b18415bda870950572be26a\n",
      "/home/mquezada/tweet_topics/event_5b171726da870923dcb04790-topic_5b19ae93da870974f0f58bc3-tweet_ids_sorted_mmr.txt\n",
      "5b171726da870923dcb04790 5b19ae93da870974f0f58bc3\n",
      "/home/mquezada/tweet_topics/event_5b171726da870923dcb04791-topic_5b19af11da87097532fd0485-tweet_ids_sorted_mmr.txt\n",
      "5b171726da870923dcb04791 5b19af11da87097532fd0485\n",
      "/home/mquezada/tweet_topics/event_5b171726da870923dcb04790-topic_5b19ae13da870974f0f58bbb-tweet_ids_sorted_mmr.txt\n",
      "5b171726da870923dcb04790 5b19ae13da870974f0f58bbb\n",
      "/home/mquezada/tweet_topics/event_5b171726da870923dcb04791-topic_5b19aefeda87097532fd0482-tweet_ids_sorted_mmr.txt\n",
      "5b171726da870923dcb04791 5b19aefeda87097532fd0482\n",
      "/home/mquezada/tweet_topics/event_5b171726da870923dcb04791-topic_5b19af15da87097532fd0486-tweet_ids_sorted_mmr.txt\n",
      "5b171726da870923dcb04791 5b19af15da87097532fd0486\n",
      "/home/mquezada/tweet_topics/event_5b171726da870923dcb04791-topic_5b19af29da87097532fd0489-tweet_ids_sorted_mmr.txt\n",
      "5b171726da870923dcb04791 5b19af29da87097532fd0489\n",
      "/home/mquezada/tweet_topics/event_5b171726da870923dcb04791-topic_5b19af02da87097532fd0483-tweet_ids_sorted_mmr.txt\n",
      "5b171726da870923dcb04791 5b19af02da87097532fd0483\n",
      "/home/mquezada/tweet_topics/event_5b171726da870923dcb04790-topic_5b19ae84da870974f0f58bc0-tweet_ids_sorted_mmr.txt\n",
      "5b171726da870923dcb04790 5b19ae84da870974f0f58bc0\n",
      "/home/mquezada/tweet_topics/event_5b171725da870923dcb0478f-topic_5b184122da870950572be266-tweet_ids_sorted_mmr.txt\n",
      "5b171725da870923dcb0478f 5b184122da870950572be266\n"
     ]
    }
   ],
   "source": [
    "files = list(data_path.glob('event_*-topic_*-tweet_ids_sorted_mmr.txt'))\n",
    "\n",
    "topics_tweetids = defaultdict(list)\n",
    "\n",
    "all_tweets = get_tweets()\n",
    "all_tweets_d = dict()\n",
    "for t in all_tweets:\n",
    "    all_tweets_d[str(t['_id'])] = t\n",
    "\n",
    "    \n",
    "for f_0 in files:\n",
    "    print(f_0)\n",
    "    _, ev, top, _, _, _ = f_0.name.split(\"_\")\n",
    "    event_id = ev.split(\"-\")[0]\n",
    "    topic_id = top.split(\"-\")[0]\n",
    "    print(event_id, topic_id)\n",
    "    \n",
    "    with f_0.open() as f:\n",
    "        for i, line in enumerate(f):\n",
    "            r_id = line[:-1]\n",
    "            topics_tweetids[topic_id].append(r_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "class TopicLabeler:\n",
    "    def __init__(self, topics_tweetids):\n",
    "        self.topics_tweetids = topics_tweetids\n",
    "        self.labeled = Counter()\n",
    "        self.to_label = {topic: list(range(len(tweets))) for topic, tweets in self.topics_tweetids.items()}\n",
    "        \n",
    "    def sample(self):\n",
    "        \"\"\"\n",
    "        sample tweet con proba inv. prop. a la fraccion de tweets etiquetados del mismo topico\n",
    "        \"\"\"\n",
    "        keys = list(self.topics_tweetids.keys())\n",
    "        \n",
    "        totals = [len(self.topics_tweetids[k]) for k in keys]\n",
    "        labeleds = [self.labeled[k] for k in keys]\n",
    "        \n",
    "        fr = np.array([labeled / total for total, labeled in zip(totals, labeleds)])  # in [0, 1]\n",
    "        probas = 1 - fr  # higher for topics with less labels\n",
    "        \n",
    "        x = 1 / sum(probas)\n",
    "        rnd = random.random()\n",
    "        p0 = 0\n",
    "        \n",
    "        #print([x * p for p in probas])\n",
    "        \n",
    "        choice = 0\n",
    "        #print(rnd)\n",
    "        for i, p1 in enumerate([x * p for p in probas]):\n",
    "            #print(p0, p0 + p1)\n",
    "            if p0 <= rnd < p0 + p1:\n",
    "                choice = i\n",
    "                break\n",
    "            p0 += p1\n",
    "        \n",
    "        topic = list(self.topics_tweetids.keys())[choice]\n",
    "        if not self.to_label[topic]:\n",
    "            return None  # done!\n",
    "        \n",
    "        #tweet = random.choice(self.to_label[topic])\n",
    "        tweet = self.to_label[topic][0]\n",
    "        return topic, tweet\n",
    "    \n",
    "    def label(self, topic_id, tweet_idx):\n",
    "        self.to_label[topic_id].remove(tweet_idx)\n",
    "        self.labeled.update({topic_id: 1})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('b', 3), 100000)]\n"
     ]
    }
   ],
   "source": [
    "tl = TopicLabeler({'a': ['x','y','z'], 'b': ['q','w','e','r'], 'c': ['t','y']})\n",
    "tl.label('a', 0)\n",
    "tl.label('a', 1)\n",
    "tl.label('a', 2)\n",
    "tl.label('b', 0)\n",
    "tl.label('b', 1)\n",
    "tl.label('b', 2)\n",
    "#tl.label('b', 3)\n",
    "tl.label('c', 0)\n",
    "tl.label('c', 1)\n",
    "sampled = Counter([tl.sample() for _ in range(100000)])\n",
    "print(sampled.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl = TopicLabeler(topics_tweetids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('5b19af11da87097532fd0485', 0)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tl.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl.label('5b19af11da87097532fd0485', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('5b18412bda870950572be267', 0)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tl.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl.label('5b18412bda870950572be267', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('5b184131da870950572be268', 0)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tl.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.75      , 0.5       , 0.66666667])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prop(np.array([1/4, 1/2, 1/3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
